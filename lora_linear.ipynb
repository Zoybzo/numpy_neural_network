{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T14:05:31.884967Z",
     "start_time": "2025-03-12T14:05:29.728456Z"
    }
   },
   "source": [
    "!pip install numpy\n",
    "!pip install loguru"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/mkpk/miniconda3/lib/python3.10/site-packages (1.26.2)\r\n",
      "Requirement already satisfied: loguru in /Users/mkpk/miniconda3/lib/python3.10/site-packages (0.7.2)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T14:05:33.783176Z",
     "start_time": "2025-03-12T14:05:33.768937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from loguru import logger"
   ],
   "id": "f3b6186a8c909848",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loguru'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mloguru\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logger\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'loguru'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lora for Linear\n",
    "实现对于 linear 层的 lora，包括前向传播，反向传播，训练API，以及推理。以 交叉熵 损失为例。"
   ],
   "id": "11958072a996275b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:37:04.967809Z",
     "start_time": "2025-03-12T15:37:04.964233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_crossentropy_loss(y_true, y_pred):\n",
    "    # 防止 log(0) 出现\n",
    "    epsilon = 1e-7\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip的作用：限制 y_pred 的范围\n",
    "    # loss\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(fx):\n",
    "    return fx * (1 - fx)"
   ],
   "id": "118ce3151da3826b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:35:40.323079Z",
     "start_time": "2025-03-12T15:35:40.309755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LoraLinear:\n",
    "    def __init__(self, in_dim, out_dim, rank=8, lr=0.01):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.rank = rank\n",
    "        self.lr = lr\n",
    "\n",
    "        # original linear layer\n",
    "        self.W = np.random.randn(in_dim, out_dim)\n",
    "        self.b = np.random.randn(1, out_dim)\n",
    "\n",
    "        # lora\n",
    "        self.A = np.random.randn(in_dim, rank)\n",
    "        self.B = np.zeros((rank, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [bs, in_dim]\n",
    "        self.linear_output = np.dot(x, self.W) + self.b\n",
    "        self.xA = np.dot(x, self.A)  # [bs, rank]\n",
    "        self.xB = np.dot(self.xA, self.B)  # [bs, out_dim]\n",
    "        self.output = self.linear_output + self.xB\n",
    "        self.a = sigmoid(self.output)\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, x, y_true, y_pred):\n",
    "        # x: [bs, in_dim]\n",
    "        error = y_pred - y_true\n",
    "        # error: [bs, out_dim]\n",
    "        self.dB = np.dot(self.xA.T, error)  # [rank, out_dim]\n",
    "        error_a = np.dot(error, self.B.T)  # [bs, rank]\n",
    "        self.dA = np.dot(x.T, error_a)  # [in_dim, rank]\n",
    "        # update\n",
    "        self.A = self.A - self.lr * self.dA\n",
    "        self.B = self.B - self.lr * self.dB\n",
    "\n",
    "    def calculate_loss(self, x, y_true):\n",
    "        y_pred = self.forward(x)\n",
    "        loss = binary_crossentropy_loss(y_true=y_true, y_pred=y_pred)\n",
    "        self.backward(x, y_true=y_true, y_pred=y_pred)\n",
    "        return loss\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.calculate_loss(X, y)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")"
   ],
   "id": "5328bb98ef46f570",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:37:07.223372Z",
     "start_time": "2025-03-12T15:37:07.189724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例数据\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # 输入\n",
    "y = np.array([[0], [1], [1], [0]])  # 二分类目标\n",
    "\n",
    "# 创建神经网络\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "rank = 1\n",
    "\n",
    "nn = LoraLinear(in_dim=input_size, out_dim=hidden_size, rank=rank, lr=0.01)\n",
    "\n",
    "# 训练网络\n",
    "nn.train(X, y, epochs=1000)\n",
    "\n",
    "# 测试\n",
    "print(\"Testing the network:\")\n",
    "for i in range(len(X)):\n",
    "    output = nn.forward(X[i:i + 1])\n",
    "    pred = 1 if output[0][0] > 0.5 else 0\n",
    "    res = bool(X[i][1] == int(pred))\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output[0][0]:.4f}, Result: {res}\")"
   ],
   "id": "3b669971c4b480f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 0.8927\n",
      "Epoch 100/1000, Loss: 0.8876\n",
      "Epoch 200/1000, Loss: 0.8375\n",
      "Epoch 300/1000, Loss: 0.7707\n",
      "Epoch 400/1000, Loss: 0.7664\n",
      "Epoch 500/1000, Loss: 0.7649\n",
      "Epoch 600/1000, Loss: 0.7642\n",
      "Epoch 700/1000, Loss: 0.7639\n",
      "Epoch 800/1000, Loss: 0.7637\n",
      "Epoch 900/1000, Loss: 0.7637\n",
      "Testing the network:\n",
      "Input: [0 0], Predicted Output: 0.3985, Result: True\n",
      "Input: [0 1], Predicted Output: 0.2771, Result: False\n",
      "Input: [1 0], Predicted Output: 0.6671, Result: False\n",
      "Input: [1 1], Predicted Output: 0.5369, Result: True\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
