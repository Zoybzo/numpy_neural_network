{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression With CrossEntropy Loss\n",
    "使用 Numpy 实现交叉熵损失的逻辑回归，包括前向传播、反向传播、损失计算、训练过程"
   ],
   "id": "3e87df7d7f5b7ebf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:50:51.533567Z",
     "start_time": "2025-03-12T13:50:50.393021Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install numpy",
   "id": "c5f779a0f180b68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/mkpk/miniconda3/lib/python3.10/site-packages (1.26.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:51:58.092489Z",
     "start_time": "2025-03-12T13:51:56.968077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!which pip\n",
    "!python -m pip install loguru"
   ],
   "id": "e2ec798b00716317",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mkpk/miniconda3/bin/pip\r\n",
      "Requirement already satisfied: loguru in /Users/mkpk/miniconda3/lib/python3.10/site-packages (0.7.2)\r\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:51:59.941332Z",
     "start_time": "2025-03-12T13:51:59.930558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from loguru import logger"
   ],
   "id": "e4c4061ba9eb4ba8",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loguru'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mloguru\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logger\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'loguru'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Entropy Loss\n",
    "二分类的交叉熵损失\n",
    "$$\n",
    "\\mathcal{L} = -(y_{true}\\log(y_{pred}) + (1-y_{true})\\log(1-y_{pred}))\n",
    "$$\n",
    "交叉熵损失的导数\n",
    "$$\n",
    "\\mathcal{L}^\\prime = -(\\frac{y_{true}}{y_{pred}} - \\frac{1-y_{true}}{1-y_{pred}}) = \\frac{y_{pred} - y_{true}}{y_{pred}(1 - y_{pred})}\n",
    "$$\n",
    "在二分类任务中不需要通过函数来定义交叉熵损失的导数，因为sigmoid会和导数的分母抵消。"
   ],
   "id": "e2217c388be448f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:52:08.875892Z",
     "start_time": "2025-03-12T13:52:08.871479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_crossentropy_loss(y_true, y_pred):\n",
    "    # 防止 log(0) 出现\n",
    "    epsilon = 1e-7\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip的作用：限制 y_pred 的范围\n",
    "    # loss\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss"
   ],
   "id": "910602c132935dac",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sigmoid",
   "id": "9f72ba02af57cf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:52:10.739222Z",
     "start_time": "2025-03-12T13:52:10.735785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(fx):\n",
    "    return fx * (1 - fx)"
   ],
   "id": "e4fb57d03938e32a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LogisticRegression",
   "id": "2bad1873b21c13ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:58:45.018180Z",
     "start_time": "2025-03-12T13:58:45.009195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, in_dim, hidden_dim, learning_rate=0.01):\n",
    "        self.in_dim = in_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w1 = np.random.randn(in_dim, hidden_dim)\n",
    "        self.b1 = np.random.randn(1, hidden_dim)\n",
    "        self.w2 = np.random.randn(hidden_dim, 1)\n",
    "        self.b2 = np.random.randn(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [bs, in_dim]\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)  # [bs, hidden_dim]\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)  # [bs, 1]\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, x, y_true, y_pred):\n",
    "        # layer2\n",
    "        error_layer2 = y_pred - y_true  # [bs, 1] # 对 z2 求导\n",
    "        dw2 = np.dot(self.a1.T, error_layer2)  # [hidden_dim, 1]\n",
    "        db2 = np.sum(error_layer2, axis=0, keepdims=True)  # [1, 1]\n",
    "        # layer1\n",
    "        error_layer1 = np.dot(error_layer2, self.w2.T) * sigmoid_derivative(\n",
    "            self.a1)  # [bs, hidden_dim] # 对 z1 求导：先对a1求导，再对 z1 求导\n",
    "        # sigmoid_derivative的参数是sigmoid(input)，所以输入 self.a1\n",
    "        dw1 = np.dot(x.T, error_layer1)  # [in_dim, hidden_dim]\n",
    "        db1 = np.sum(error_layer1, axis=0, keepdims=True)  # [1, hidden_dim]\n",
    "        # update\n",
    "        self.w2 -= self.learning_rate * dw2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.w1 -= self.learning_rate * dw1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "        output = self.forward(X)\n",
    "        loss = binary_crossentropy_loss(y_true=y, y_pred=output)\n",
    "        self.backward(X, y_true=y, y_pred=output)\n",
    "        return loss\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.calculate_loss(X, y)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}\")"
   ],
   "id": "87dd0f1cb2221041",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:59:47.661005Z",
     "start_time": "2025-03-12T13:59:47.619451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例数据\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # 输入\n",
    "y = np.array([[0], [1], [1], [0]])  # 二分类目标\n",
    "\n",
    "# 创建神经网络\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "\n",
    "nn = LogisticRegression(input_size, hidden_size, output_size)\n",
    "\n",
    "# 训练网络\n",
    "nn.train(X, y, epochs=1000)\n",
    "\n",
    "# 测试\n",
    "print(\"Testing the network:\")\n",
    "for i in range(len(X)):\n",
    "    output = nn.forward(X[i:i + 1])\n",
    "    pred = 1 if output[0][0] > 0.5 else 0\n",
    "    res = bool(X[i][1] == int(pred))\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output[0][0]:.4f}, Result: {res}\")"
   ],
   "id": "eb1821b42e5c468d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 1.1382\n",
      "Epoch 100/1000, Loss: 0.3747\n",
      "Epoch 200/1000, Loss: 0.0287\n",
      "Epoch 300/1000, Loss: 0.0115\n",
      "Epoch 400/1000, Loss: 0.0070\n",
      "Epoch 500/1000, Loss: 0.0050\n",
      "Epoch 600/1000, Loss: 0.0038\n",
      "Epoch 700/1000, Loss: 0.0031\n",
      "Epoch 800/1000, Loss: 0.0026\n",
      "Epoch 900/1000, Loss: 0.0023\n",
      "Testing the network:\n",
      "Input: [0 0], Predicted Output: 0.0004, Result: True\n",
      "Input: [0 1], Predicted Output: 0.9987, Result: True\n",
      "Input: [1 0], Predicted Output: 0.9974, Result: False\n",
      "Input: [1 1], Predicted Output: 0.0036, Result: False\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
